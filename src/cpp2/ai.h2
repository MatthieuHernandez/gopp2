#include "player.h2"
#include "snn.h2"

createAi:() = {
    /*layers: std::vector<snn::LayerModel> = (snn::Input(1, 9, 9),
                                            snn::FullyConnected(2000, snn::activation::ReLU),
                                            snn::FullyConnected(2000, snn::activation::ReLU),
                                            snn::FullyConnected(81, snn::activation::tanh));*/
    /*layers: std::vector<snn::LayerModel> = (snn::Input(1, 9, 9),
                                            snn::Convolution(16, 5, snn::activation::ReLU, 0.0F),
                                            snn::Convolution(64, 3, snn::activation::GELU, 0.0F),
                                            snn::Convolution(256, 3, snn::activation::GELU, 0.0F),
                                            snn::FullyConnected(81, snn::activation::tanh));*/
    layers: std::vector<snn::LayerModel> = (snn::Input(1, 9, 9),
                                            snn::Convolution(16, 3, snn::activation::GELU),
                                            snn::Convolution(64, 3, snn::activation::GELU),
                                            snn::FullyConnected(81, snn::activation::tanh));
    optimizer:= snn::StochasticGradientDescent(1e-4f, 0.0f);
    neuralNetwork:= snn::StraightforwardNeuralNetwork(layers, optimizer);
    neuralNetwork.saveAs("./snn_models/9x9/TM_AG_02.snn");
    if neuralNetwork.isValid() != snn::errorType::noError {
        std::cout << "INVALID MODEL !" << std::endl;
        std::exit(0);
    }
    std::cout << "AI created." << std::endl;
}

Ai: type = {
    this: Player;
    public topK: i16; // Randomly select a move from the K best moves.
    public margin: i8; // Randomly select a move with less than N percentage margin from the best move.
    public learningRate: float = 1e-4f;

    private modelPath: std::string;
    private neuralNetwork: std::shared_ptr<snn::StraightforwardNeuralNetwork>;
    private optimizer: std::shared_ptr<snn::internal::StochasticGradientDescent>;
    private lastGameWon: std::deque<int>;
    private lastBlackGameWon: std::deque<int>;
    private numberOfGames: size_t = 1000; // To calculate winrate.
    private sumOfLastGameWon: size_t = 0;
    private sumOfLastBlackGameWon: size_t = 0;
    private previousWinrate: float = 0.0f;
    private isBetter: bool = false;

    public operator=:(out this, i: *Interface, c: Color, path: std::string) = {
        Player = (i, c);
        topK = 1;
        margin = 0;
        modelPath = path;
        neuralNetwork = shared.new<snn::StraightforwardNeuralNetwork>(snn::StraightforwardNeuralNetwork::loadFrom(modelPath));
        optimizer = std::static_pointer_cast<snn::internal::StochasticGradientDescent>(neuralNetwork*.optimizer);
        lastGameWon = ();
        lastBlackGameWon = ();
    }

    public operator=:(out this, i: *Interface, c: Color, in ai: Ai) = {
        Player = (i, c);
        topK = ai.topK;
        margin = ai.margin;
        modelPath = "";
        neuralNetwork = ai.neuralNetwork;
        optimizer = std::static_pointer_cast<snn::internal::StochasticGradientDescent>(neuralNetwork*.optimizer);
        lastGameWon = ();
        lastBlackGameWon = ();
    }

    public operator=:(out this, that) = {
        Player = (that);
        topK = that.topK;
        margin = that.margin;
        neuralNetwork = that.neuralNetwork;
        optimizer = that.optimizer;
        modelPath = that.modelPath;
        lastGameWon = that.lastGameWon;
        sumOfLastGameWon = that.sumOfLastGameWon;
        lastBlackGameWon = that.lastBlackGameWon;
        sumOfLastBlackGameWon = that.sumOfLastBlackGameWon;
        learningRate = that.learningRate;
        previousWinrate = that.previousWinrate;
        isBetter = that.isBetter;
    }

    public summary:(in this) -> std::string = {
        return neuralNetwork*.summary();
    }

    private getGobanState:<Size: i8>(in state: State<Stone, Size>, in c: Color) -> std::vector<float> = {
        vec: std::vector<float> = ();
        size:= state.ssize() * state.ssize();
        vec.reserve(size);
        (copy col: i8 = 0)
        while col < state.ssize()
        next col++
        {
            (copy row: i8 = 0)
            while row < state[col].ssize()
            next row++
            {
                if state[col][row].color == c {
                    if c == ColorBlack {
                        vec.push_back(0.9);
                    } else {
                        vec.push_back(1.1);
                    }
                } else if state[col][row].color == ColorNone {
                    vec.push_back(0.0);
                } else {
                    if c == ColorBlack {
                        vec.push_back(-0.9);
                    } else {
                        vec.push_back(-1.1);
                    }
                }
            }
        }
        return vec;
    }

    private chooseBestMove:<Size: i8>(inout this, in nnOutput: std::vector<float>, inout engine: Engine<Size>) -> Move = {
        index: i16 = 0;
        estimatedPositions: std::vector<Stone> = ();
        numberOfPositions:= Size * Size;
        estimatedPositions.reserve(numberOfPositions);
        (copy col: i8 = 0)
        while col < Size
        next col++
        {
            (copy row: i8 = 0)
            while row < Size
            next row++
            {
                estimation:= nnOutput[index];
                stone:=  Stone(color, col, row, estimation);
                estimatedPositions.push_back(stone);
                index++;
            }
        }
        std::ranges::sort(estimatedPositions, std::ranges::greater(), Stone::estimation&);

        count: i16 = 0;
        best: float = estimatedPositions[0].estimation;
        if best > 0 {
            while count < numberOfPositions
            next count++
            {
                current:= estimatedPositions[count].estimation;
                if current < best * (1.0f - (margin / 100.0f)) {
                    break;
                }
            }
        }
        pickSize:= std::max((topK-1) as i64, count as i64);
        dist: std::uniform_int_distribution<i64> = (0, pickSize);
        pickedIndex:= dist(rng);
        s:= estimatedPositions[pickedIndex];
        m:= Move(s);
        if engine.isValidMove(m) {
            return m;
        }
        (copy index2: i16 = 0)
        while index2 < numberOfPositions
        next index2++
        {
            if (index2 != pickedIndex) { // TODO: MAYBE A BUG HERE
                s2:= estimatedPositions[index2];
                m2:= Move(s2);
                if engine.isValidMove(m2) {
                    return m2;
                }
            }
        }
        return Move::pass(color);
    }

    private getMove:<Size: i8>(inout this, inout engine: Engine<Size>) -> Move = {
        input:= getGobanState<Size>(engine.goban.state, color);
        output:= neuralNetwork*.computeOutput(input);
        m:= chooseBestMove<Size>(output, engine);
        return m;
    }

    public getMove:(override inout this, inout engine: Engine<9>) -> Move = {
        return getMove<9>(engine);
    }

    public getMove:(override inout this, inout engine: Engine<13>) -> Move = {
        return getMove<13>(engine);
    }

    public getMove:(override inout this, inout engine: Engine<19>) -> Move = {
        return getMove<19>(engine);
    }

    private computeLearningRate:(inout this, numberOfMoves: size_t)-> float = {
        if lastGameWon.ssize() < 100 {
            return learningRate;
        }
        newLearningRate:= learningRate;
        winrate := calculateWinRate();
        if winrate < 1.0F && (hasWon && winrate > 0.5F) {
            newLearningRate *= (1.0F - winrate) / winrate;
        }
        blackWinrate := calculateBlackWinRate();
        blackHasWon := (hasWon && color == ColorBlack) || (!hasWon && color == ColorWhite);
        if blackHasWon && blackWinrate < 1.0F && blackWinrate > 0.5F {
            newLearningRate *= (1.0F - blackWinrate) / blackWinrate;
        }
        whiteWinrate := 1 - blackWinrate;
        if !blackHasWon && whiteWinrate < 1.0F && whiteWinrate > 0.5F {
            newLearningRate *= (1.0F - whiteWinrate) / whiteWinrate;
        }
        return newLearningRate;
    }

    public train:<Size: i8>(inout this, in engine: Engine<Size>) = {
        numberOfMoves := engine.moves.ssize();
        distRotate: std::uniform_int_distribution<i64> = (0, 3);
        distFlip: std::uniform_int_distribution<i64> = (4, 6);
        gameLength: i16 = unchecked_narrow<i16>(engine.moves.size());
        optimizer*.learningRate = computeLearningRate(numberOfMoves);
        size:= Size * Size;
        expectedBlack: float;
        expectedWhite: float;
        if (hasWon && color == ColorBlack) ||
           (!hasWon && color == ColorWhite) {  // CPP2 workaround: Conditional operator not yet supported.
            expectedBlack = 1.0f;
            expectedWhite = -1.0f;
        } else {
            expectedBlack = -1.0f;
            expectedWhite = 1.0f;
        }
        //(copy i: i16 = unchecked_narrow<i16>(engine.moves.size() - 6))
        i: i16 = 0;
        /*if engine.moves.ssize() >= 30 {
            i = engine.moves.size() - 30;
        }*/
        while i < (engine.moves.ssize())
        next i++
        {
            if (engine.moves[i].isPass == true) {
                return;
            }
            inputs: std::vector<float> = ();
            expectedIndex: i16 = ();
            (copy t: i16 = 1)
            while t < 2
            next t++
            {
                state := engine.states[i];
                stone := engine.moves[i].stone;
                if t == 0 {
                    inputs = getGobanState<Size>(state, stone.color);
                    expectedIndex = stone.getIndex<Size>();
                } else if t == 1 {
                    t1 := Transformation(distRotate(rng));
                    t2 := Transformation(distFlip(rng));
                    // Rotate and Flip the goban state.
                    state = transformState<Size>(state, t1);
                    state = transformState<Size>(state, t2);
                    inputs = getGobanState<Size>(state, stone.color);
                    // Rotate and Flip the stone played.
                    stone.transform<Size>(t1);
                    stone.transform<Size>(t2);
                    expectedIndex = stone.getIndex<Size>();
                } else {
                    return;
                }
                expectedOutputs:= std::vector<float>(size, NAN);
                weighting:= std::vector<float>(size, 1.0f);
                (copy j: i16 = 0)
                while j < size
                next j++
                {
                    if inputs[j] != 0.0 {
                        expectedOutputs[j] = 0;
                        weighting[j] = 1e-3f;
                    }
                }
                if i % 2 == 0 {
                    expectedOutputs[expectedIndex] = expectedBlack;
                } else {
                    expectedOutputs[expectedIndex] = expectedWhite;
                }
                neuralNetwork*.trainOnce(inputs, expectedOutputs, weighting);
            }
        }
    }

    public save:(inout this, onlyIfBetter: bool) = {
        if neuralNetwork*.isValid() != snn::errorType::noError {
            std::cout << "INVALID MODEL !" << std::endl;
            std::exit(0);
        }
        if !onlyIfBetter || isBetter {
            neuralNetwork*.saveAs(modelPath);
            isBetter = false;
        }
    }

    public resetWinRate:(inout this) = {
        lastGameWon.clear();
        lastBlackGameWon.clear();
        sumOfLastGameWon = 0;
        sumOfLastBlackGameWon = 0;
    }

    public calculateWinRate:(in this) -> float = {
        if (!lastGameWon.empty()) {
            return sumOfLastGameWon / (float)(lastGameWon.size());
        }
        return -1;
    }
    
    public calculateBlackWinRate:(in this) -> float = {
        if (!lastBlackGameWon.empty()) {
            return sumOfLastBlackGameWon / (float)(lastBlackGameWon.size());
        }
        return -1;
    }

    public processStartGame:(override inout this) = {
        currentWinRate:= calculateWinRate();
        if lastGameWon.ssize() == numberOfGames
        && currentWinRate > previousWinrate {
            previousWinrate = currentWinRate;
            isBetter = true;

        }
    }

    public processEndGame:(override inout this, refreshInterface: bool) = {
        if hasWon {  // CPP2 workaround: Conditional operator not yet supported.
            lastGameWon.push_back(1);
            sumOfLastGameWon += 1;
        } else {
            lastGameWon.push_back(0);
        }
        if (hasWon && color == ColorBlack) ||
           (!hasWon && color == ColorWhite)  { // If black won the game.
            lastBlackGameWon.push_back(1);
            sumOfLastBlackGameWon += 1;
        } else {
            lastBlackGameWon.push_back(0);
        }
        if (lastGameWon.size() > numberOfGames) {
            sumOfLastGameWon -= lastGameWon.front();
            sumOfLastBlackGameWon -= lastBlackGameWon.front();
            lastGameWon.pop_front();
            lastBlackGameWon.pop_front();
        }
        if refreshInterface {
            if lastGameWon.ssize() > 100 {
                interface*.printLater("AI winrate:    "+ std::to_string(calculateWinRate() * 100.0f) +" %");
                interface*.printLater("Black winrate: "+ std::to_string(calculateBlackWinRate() * 100.0f) +" %");
            } else {
                interface*.printLater("AI winrate:    ...");
                interface*.printLater("Black winrate: ...");
            }
            oss: std::ostringstream = ();
            oss << "AI learning rate: " << std::scientific << std::setprecision(2) << optimizer*.learningRate;
            interface*.printLater(oss.str());
            interface*.printLater("AI Top-k: " + std::to_string(topK));
        }
    }
}
