#include "player.h2"
#include "io.h2"
#include <snn/neural_network/StraightforwardNeuralNetwork.hpp>

createAi:() = {
    layers: std::vector<snn::LayerModel> = (snn::Input(1, 9, 9),
                                            snn::FullyConnected(500, snn::activation::ReLU),
                                            snn::FullyConnected(500, snn::activation::ReLU),
                                            snn::FullyConnected(81, snn::activation::tanh));
    optimizer:= snn::StochasticGradientDescent(1e-5f, 0.0f);
    neuralNetwork:= snn::StraightforwardNeuralNetwork(layers, optimizer);
    neuralNetwork.saveAs("./snn_models/9x9/model_v9.snn");
}                                                                                                                               

Ai: type = {
    this: Player;
    public randomness: i16; // Randomly select a move from the N best moves.

    private modelPath: std::string;
    private neuralNetwork: snn::StraightforwardNeuralNetwork;
    private optimizer: std::shared_ptr<snn::internal::StochasticGradientDescent>;
    private inputs: snn::vector2D<float>;
    private moves: std::vector<i16>;
    private lastGameWon: std::deque<int>;
    private numberOfGames: const size_t = 1000; // To calculate winrate.
    private sumOfLastGameWon: size_t = 0;
    private learningRateUpdateRatio: float = 0.5f;
    private previousWinrate: float = 0.0f;
    private isBetter: bool = false;

    public operator=:(out this, c: Color, r: i16, path: std::string) = {
        Player = (c);
        randomness = r;
        modelPath = path;
        neuralNetwork = snn::StraightforwardNeuralNetwork::loadFrom(modelPath);
        optimizer = std::static_pointer_cast<snn::internal::StochasticGradientDescent>(neuralNetwork.optimizer);
        inputs = ();
        moves = ();
        lastGameWon = ();
        inputs.reserve(300);
        moves.reserve(300);
        optimizer*.learningRate = 1e-8f;
    }

    public operator=:(out this, that) = {
        Player = (that);
        randomness = that.randomness;
        neuralNetwork = that.neuralNetwork;
        optimizer = that.optimizer;
        inputs = that.inputs;
        moves = that.moves;
        modelPath = that.modelPath;
        lastGameWon = that.lastGameWon;
        sumOfLastGameWon = that.sumOfLastGameWon;
        learningRateUpdateRatio = that.learningRateUpdateRatio;
        previousWinrate = that.previousWinrate;
        isBetter = that.isBetter;
    }

    public summary:(in this) -> std::string = {
        return neuralNetwork.summary();
    }

    private getGobanState:<Size: i8>(in this, in state: State<Stone, Size>) -> std::vector<float> = {
        vec: std::vector<float> = ();
        size:= state.ssize() * state.ssize();
        vec.reserve(size);
        (copy col: i8 = 0)
        while col < state.ssize()
        next col++
        {
            (copy row: i8 = 0)
            while row < state[col].ssize()
            next row++
            {
                if state[col][row].color == color {
                    vec.push_back(1.0);
                }
                else if state[col][row].color == Color::None {
                    vec.push_back(0.0);
                }
                else {
                    vec.push_back(-1.0);
                }
            }
        }
        return vec;
    }

    private chooseBestMove:<Size: i8>(inout this, in nn_output: std::vector<float>) -> Move = {
        index: i16 = 0;
        estimatedPositions: std::vector<Stone> = ();
        numberOfPositions:= Size * Size;
        estimatedPositions.reserve(numberOfPositions);
        (copy col: i8 = 0)
        while col < Size
        next col++
        {
            (copy row: i8 = 0)
            while row < Size
            next row++
            {
                estimation:= nn_output[index];
                stone:=  Stone(color, col, row, estimation);
                estimatedPositions.push_back(stone);
                index++;
            }
        }
        std::ranges::sort(estimatedPositions, std::ranges::greater(), Stone::estimation&);
        dist: std::uniform_int_distribution<i64> = (0, randomness-1);
        s:= estimatedPositions[0];
        return Move(s);
    }

    private getMove:<Size: i8>(inout this, inout engine: Engine<Size>) -> Move = {
        input:= getGobanState<Size>(engine.goban.state);
        output:= neuralNetwork.computeOutput(input);
        m:= chooseBestMove<Size>(output);
        engine.closerValidMove(m);
        moveIndex:= m.stone.getIndex<Size>();
        if moveIndex >= 0 {
            inputs.push_back(input);
            moves.push_back(moveIndex);
        }
        return m;
    }

    public getMove:(override inout this, inout engine: Engine<9>) -> Move = {
        return getMove<9>(engine);
    }

    public getMove:(override inout this, inout engine: Engine<19>) -> Move = {
        return getMove<19>(engine);
    }

    public train:(inout this, gobanSize: i16) = {
        if inputs.ssize() > 75 { // Only train on "short" game.
            return;
        }
        if randomness == 1 && lastGameWon.ssize() > 100 { // Only process on "accurate" game.
            winrate:= calculateWinrate();
            if !hasWon {
                optimizer*.learningRate = 1e-7f * winrate;
            } else {
                optimizer*.learningRate = 1e-7f * (1- winrate);
            }
        }
        size:= gobanSize * gobanSize;
        expectedValue: float = -1.0f;
        if hasWon { // CPP2 workaround: Conditional operator not yet supported.
            expectedValue = 1.0f;
        }
        (copy i: i16 = 0)
        while i < inputs.ssize()
        next i++
        {
            expected_output:= std::vector<float>(size, NAN);
            (copy j: i16 = 0)
            while j < size
            next j++
            {
                if inputs[i][j] != 0.0 {
                    expected_output[j] = 0;
                }
            }
            expected_output[moves[i]] = expectedValue;
            neuralNetwork.trainOnce(inputs[i], expected_output);
        }
    }
    
    public saveIfBetter:(inout this) = {
        if isBetter {
            neuralNetwork.saveAs(modelPath);
            isBetter = false;
        }
    }

    private calculateWinrate:(in this) -> float = {
        return sumOfLastGameWon / (float)(lastGameWon.size());
    }

    public processStartGame:(override inout this) = {
        inputs.clear();
        moves.clear();
        currentWinRate:= calculateWinrate();
        if lastGameWon.ssize() == numberOfGames
        && currentWinRate > previousWinrate {
            previousWinrate = currentWinRate;
            isBetter = true;

        }
    }

    public processEndGame:(override inout this) = {
        if randomness == 1 { // Only process on "accurate" game.
            if hasWon { // CPP2 workaround: Conditional operator not yet supported.
                lastGameWon.push_back(1);
                sumOfLastGameWon += 1;
            } else {
                lastGameWon.push_back(0);
            }
            if (lastGameWon.size() > numberOfGames) {
                sumOfLastGameWon -= lastGameWon.front();
                lastGameWon.pop_front();
            }
        }
        if lastGameWon.ssize() > 100 {
            setNextMessage("AI winrate: "+ std::to_string(calculateWinrate() * 100.0f) +" %");
        } else {
            setNextMessage("AI winrate: ...");
        }
        oss: std::ostringstream = ();
        oss << "AI learning rate: " << std::scientific << std::setprecision(2) << optimizer*.learningRate;
        setNextMessage(oss.str());
    }
}
